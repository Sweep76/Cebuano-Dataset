# Token types
#
# EOF (end-of-file) token is used to indicate that
# there is no more inpput left for lexical analysis
TOKEN_CONJ = "CONJ" #
TOKEN_DET = "DET" #
TOKEN_DET_PLURAL = "DET_PLURAL" #
TOKEN_PART = "PART"
TOKEN_PRON_DEM = "PRON_DEM" #
TOKEN_PRON_POS = "PRON_POS" #
TOKEN_PRON_POS_NG = "PRON_POS_NG" #
TOKEN_PRON_POS_N = "PRON_POS_N" #
TOKEN_PRON_PER = "PRON_PER" #
TOKEN_NOUN = "NOUN" #
TOKEN_PREP = "PREP" #
TOKEN_VERB = "VERB" # 
TOKEN_VERB_EXT = "VERB_EXT"
TOKEN_ADJ = "ADJ" # 
TOKEN_ADV_SPE = "ADV_SPE" #
TOKEN_ADV = "ADV" #
TOKEN_PART_PLURAL = "PART_PLURAL"
TOKEN_PRON_PLURAL = "PRON_PLURAL"
TOKEN_PRON_PER_PLURAL = "PRON_PER_PLURAL" #
TOKEN_PRON_POS_PLURAL = "PRON_POS_PLURAL" #
TOKEN_PRON_POS_PLURAL_NG = "PRON_POS_PLURAL_NG" #
TOKEN_PRON_POS_PLURAL_N = "PRON_POS_PLURAL_N" #
TOKEN_VERB_PREF_PRES = "VERB_PREF_PRES" #
TOKEN_VERB_PREF_PAST = "VERB_PREF_PAST" #
TOKEN_VERB_PREF_FUT = "VERB_PREF_FUT" #
TOKEN_VERB_SUFF_PRES = "VERB_SUFF_PRES" #
TOKEN_VERB_SUFF_PAST = "VERB_SUFF_PAST" #
TOKEN_VERB_SUFF_FUT = "VERB_SUFF_FUT" #
TOKEN_NUM = "NUM" #
TOKEN_MGA = "MGA" #
TOKEN_KA = "KA" #
TOKEN_AN = "AN" #
TOKEN_IKA = "IKA" #
TOKEN_NGA = "NGA" #
TOKEN_CLIT_Y = "CLIT_Y" #
TOKEN_CLIT_NG = "CLIT_NG" #
TOKEN_DILI = "DILI"
TOKEN_I = "I"
TOKEN_A = "A"
TOKEN_HA = "HA"
TOKEN_UG = "UG"
TOKEN_HI = "HI"
TOKEN_TIME_FUT = "TIME_FUT"
TOKEN_TIME_PAST = "TIME_PAST"
TOKEN_TIME_PRES = "TIME_PRES"
TOKEN_NIAGING = "NIAGING" #
TOKEN_SUNOD = "SUNOD" #
TOKEN_POS_LINK = "POS_LINK" #
TOKEN_KARONG = "KARONG" #
TOKEN_TIME_NOUN = "TIME_NOUN" #
TOKEN_TIME_NOUN_A = "TIME_NOUN_A" #
TOKEN_TIME = "TIME" #
TOKEN_DASH = "DASH" #
TOKEN_COMMA = "COMMA" #
TOKEN_MONTH = "MONTH" #
TOKEN_DAY = "DAY" #
TOKEN_TIME_OF_DAY = "TIME_OF_DAY" #
TOKEN_IMPERATIVE = "IMPERATIVE" #
TOKEN_YEAR = "YEAR" #
TOKEN_INT = "INT" #
TOKEN_HOUR = "HOUR" #
TOKEN_ANG = "ANG"
TOKEN_EOF = "EOF"
TOKEN_PLACE = "PLACE" #